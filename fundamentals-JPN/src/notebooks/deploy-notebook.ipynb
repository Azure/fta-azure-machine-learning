{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Azure Machine Learning による機械学習プロセス - デプロイ編"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## アジェンダ\n",
        "### A. 学習編\n",
        "- ワークスペース (Workspace) への接続\n",
        "- データセット (Datasets) の登録\n",
        "- 環境 (Environments) の登録\n",
        "- コンピューティングクラスター (Compute Clusters) の作成\n",
        "- モデル学習の実行と実験 (Run & Experiments)\n",
        "- モデル登録 (Models)\n",
        "\n",
        "### **B. デプロイ編 (本ノートブック)**\n",
        "- ワークスペース (Workspace) への接続\n",
        "- 推論環境の作成 (Deployment)\n",
        "- エンドポイントの利用 (Endpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 事前設定\n",
        "- 本ノートブックは Azure Machine Learning の Compute Instance を利用することを想定しています。\n",
        "- 開発環境は JupyterLab, VSCode, Integrated Notebook など Compute Instance で稼働するものであれば自由に選択いただけます。\n",
        "- カーネルは `python38-azureml (Python 3.8 AzureML)` を選択ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ワークスペース (Workspace) への接続\n",
        "作業環境から Azure Machine Learning Workspace へ接続を行います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Azure Machine Learning Studio\n",
        "[ml.azureml.com](ml.azurem.com) にアクセスします。Python SDK を中心に作業される場合にも Azure Machine Learning Studio を併用することが多いです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"../docs/images/azureml-workspace.png\" width=500>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Python SDK での手順\n",
        "クライアント環境の Python 環境にインストールした Azure ML Python SDK を用いて Azure Machine Learning Workspace に接続します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1649081976581
        }
      },
      "outputs": [],
      "source": [
        "# Compute Instance を利用する場合\n",
        "from azureml.core import Workspace\n",
        "ws = Workspace.from_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1649081976640
        }
      },
      "outputs": [],
      "source": [
        "# # その他の任意のクライアント環境を利用する場合\n",
        "# ws = Workspace.get(\n",
        "#     name='name',\n",
        "#     subscription_id='subscription_id',\n",
        "#     resource_group='resource_group',\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 推論環境の作成 (Deployment)\n",
        "下記の情報を利用してモデルをデプロイし、推論環境を作成します。\n",
        "- 登録済みのモデル (Model)\n",
        "- 推論環境で稼働する環境 (Environments)\n",
        "- 推論スクリプト : _score.py_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Python SDK での手順"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1649081976707
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.environment import Environment\n",
        "from azureml.core import Model\n",
        "from azureml.core.webservice import LocalWebservice, AciWebservice\n",
        "from azureml.core.model import InferenceConfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 登録済みのモデル (Models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1649081977548
        }
      },
      "outputs": [],
      "source": [
        "model = Model(ws, \"lgb-model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 推論環境で稼働する環境 (Environments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1649081977662
        }
      },
      "outputs": [],
      "source": [
        "env = Environment.get(ws, \"lightgbm-python-env\")\n",
        "#env.inferencing_stack_version = 'latest'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1649081977755
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\n",
              "    \"databricks\": {\n",
              "        \"eggLibraries\": [],\n",
              "        \"jarLibraries\": [],\n",
              "        \"mavenLibraries\": [],\n",
              "        \"pypiLibraries\": [],\n",
              "        \"rcranLibraries\": []\n",
              "    },\n",
              "    \"docker\": {\n",
              "        \"arguments\": [],\n",
              "        \"baseDockerfile\": null,\n",
              "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220208.v1\",\n",
              "        \"baseImageRegistry\": {\n",
              "            \"address\": null,\n",
              "            \"password\": null,\n",
              "            \"registryIdentity\": null,\n",
              "            \"username\": null\n",
              "        },\n",
              "        \"enabled\": false,\n",
              "        \"platform\": {\n",
              "            \"architecture\": \"amd64\",\n",
              "            \"os\": \"Linux\"\n",
              "        },\n",
              "        \"sharedVolumes\": true,\n",
              "        \"shmSize\": null\n",
              "    },\n",
              "    \"environmentVariables\": {\n",
              "        \"AZUREML_ENTRY_SCRIPT\": \"script/score.py\",\n",
              "        \"AZUREML_SOURCE_DIRECTORY\": \"script\",\n",
              "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
              "    },\n",
              "    \"inferencingStackVersion\": null,\n",
              "    \"name\": \"lightgbm-python-env\",\n",
              "    \"python\": {\n",
              "        \"baseCondaEnvironment\": null,\n",
              "        \"condaDependencies\": {\n",
              "            \"channels\": [\n",
              "                \"anaconda\",\n",
              "                \"conda-forge\"\n",
              "            ],\n",
              "            \"dependencies\": [\n",
              "                \"python=3.8\",\n",
              "                {\n",
              "                    \"pip\": [\n",
              "                        \"lightgbm==3.3.1\",\n",
              "                        \"matplotlib==3.5.1\",\n",
              "                        \"scikit-learn==1.0.2\",\n",
              "                        \"pandas==1.4.2\",\n",
              "                        \"ipykernel==6.12.1\",\n",
              "                        \"pytest==7.1.1\",\n",
              "                        \"inference-schema[numpy-support]==1.3.2\",\n",
              "                        \"azureml-mlflow==1.40.0\",\n",
              "                        \"azureml-dataprep==3.0.1\",\n",
              "                        \"azureml-defaults==1.40.0\"\n",
              "                    ]\n",
              "                }\n",
              "            ],\n",
              "            \"name\": \"azureml_5d2a131ca6625ee301a6ddb4e2abfbec\"\n",
              "        },\n",
              "        \"condaDependenciesFile\": null,\n",
              "        \"interpreterPath\": \"python\",\n",
              "        \"userManagedDependencies\": false\n",
              "    },\n",
              "    \"r\": null,\n",
              "    \"spark\": {\n",
              "        \"packages\": [],\n",
              "        \"precachePackages\": true,\n",
              "        \"repositories\": []\n",
              "    },\n",
              "    \"version\": \"16\"\n",
              "}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 推論スクリプト _score.py_\n",
        "`script` フォルダに予め作成済みです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from helper import data_preprocess\n",
        "\n",
        "\n",
        "\n",
        "def init():\n",
        "    global bst\n",
        "    model_root = os.getenv(\"AZUREML_MODEL_DIR\")\n",
        "    # 学習済みモデルを含むフォルダ名の指定\n",
        "    lgbm_model_folder = \"model\"\n",
        "    bst = lgb.Booster(\n",
        "        model_file=os.path.join(model_root, lgbm_model_folder, \"model.lgb\")\n",
        "    )\n",
        "\n",
        "def run(raw_data):\n",
        "    categorical_cols = ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
        "    float_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "    columns = bst.feature_name()\n",
        "    data = np.array(json.loads(raw_data)[\"data\"])\n",
        "    test_df_original = pd.DataFrame(data=data, columns=columns)\n",
        "    test_df = data_preprocess(test_df_original, categorical_cols, float_cols)\n",
        "    # 予測値の生成\n",
        "    out = bst.predict(test_df)\n",
        "    return out.tolist()\n",
        "\n",
        "````"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "コードや環境 (Environments) の情報を設定します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1649081977843
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "inference_config = InferenceConfig(entry_script=\"score.py\", source_directory=\"script\", environment=env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "最初にローカル環境にデプロイをします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1649082310789
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading model lgb-model:3 to /tmp/azureml_gy6lj6_p/lgb-model/3\n",
            "Generating Docker build context.\n",
            "Package creation Succeeded\n",
            "Logging into Docker registry ftamlacrnwdem.azurecr.io\n",
            "Logging into Docker registry ftamlacrnwdem.azurecr.io\n",
            "Building Docker image from Dockerfile...\n",
            "Step 1/5 : FROM ftamlacrnwdem.azurecr.io/azureml/azureml_e51c371367728f42a881ccad677344ed\n",
            " ---> 6f9f959b4c84\n",
            "Step 2/5 : COPY azureml-app /var/azureml-app\n",
            " ---> 3689828ce76f\n",
            "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjljMGY5MWI4LWViMmYtNDg0Yy05NzljLTE1ODQ4YzA5OGE2YiIsInJlc291cmNlR3JvdXBOYW1lIjoiZnRhLW1sIiwiYWNjb3VudE5hbWUiOiJmdGFtbGF6dXJlbWwiLCJ3b3Jrc3BhY2VJZCI6IjRiNzYxNzk0LTQ1OWYtNDc2MS1hZWFjLTVjNzRjZTM3YWZkZCJ9LCJtb2RlbHMiOnt9LCJtb2RlbHNJbmZvIjp7fX0= | base64 --decode > /var/azureml-app/model_config_map.json\n",
            " ---> Running in d4cbf3686ccb\n",
            " ---> 5948f4fab156\n",
            "Step 4/5 : RUN mv '/var/azureml-app/tmp7m89nvmj.py' /var/azureml-app/main.py\n",
            " ---> Running in a1610d329955\n",
            " ---> 8ca95c816f8b\n",
            "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
            " ---> Running in d349b06b211a\n",
            " ---> 4c158c4eca52\n",
            "Successfully built 4c158c4eca52\n",
            "Successfully tagged mylocalmodel:latest\n",
            "Container has been successfully cleaned up.\n",
            "Image sha256:fa0c01f6e93fd182c1503094c8cc487e5f3b0b60b134269911030cfc98b5419e successfully removed.\n",
            "Starting Docker container...\n",
            "Docker container running.\n"
          ]
        }
      ],
      "source": [
        "localconfig = LocalWebservice.deploy_configuration(port=8890)\n",
        "local_service_name = \"mylocalmodel\"\n",
        "local_service = Model.deploy(\n",
        "    workspace=ws,\n",
        "    name=local_service_name,\n",
        "    models=[model],\n",
        "    inference_config=inference_config,\n",
        "    deployment_config=localconfig,\n",
        "    overwrite=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "テストデータを入力して予測値を算出します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1649082511636
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking container health...\n",
            "Local webservice is running at http://localhost:8890\n",
            "[[0.7252904642292589, 0.2747095357707411]]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# テストデータ\n",
        "data =  {\n",
        "            \"data\": [[\n",
        "                2,\n",
        "                \"Kvillner, Mr. Johan Henrik Johannesson\",\n",
        "                \"male\",\n",
        "                31,\n",
        "                0,\n",
        "                0,\n",
        "                \"C.A. 18723\",\n",
        "                10.5,\n",
        "                \"\",\n",
        "                \"S\"\n",
        "            ]]\n",
        "        }\n",
        "\n",
        "test_sample = json.dumps(data)\n",
        "test_sample = str.encode(test_sample, encoding='utf8')\n",
        "\n",
        "prediction = local_service.run(input_data=test_sample)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "次に Azure Container Instance へデプロイをします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1649082516974
        }
      },
      "outputs": [],
      "source": [
        "aciconfig = AciWebservice.deploy_configuration(auth_enabled=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Azure Container Instance にモデルをデプロイします。<br>\n",
        "なお、`service_name` は文字から始まる 3 以上 32 小文字・数字・記号 (ダッシュのみ)で記載ください。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1649082517621
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "aciconfig.validate_configuration()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1649082524737
        }
      },
      "outputs": [],
      "source": [
        "service_name = \"lgb-aci\"  # グループで作業している場合は、名前を変更してください\n",
        "service = Model.deploy(\n",
        "    workspace=ws,\n",
        "    name=service_name,\n",
        "    models=[model],\n",
        "    inference_config=inference_config,\n",
        "    deployment_config=aciconfig,\n",
        "    overwrite=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1649084385605
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2022-04-06 14:45:03+00:00 Creating Container Registry if not exists.\n",
            "2022-04-06 14:45:04+00:00 Registering the environment.\n",
            "2022-04-06 14:45:04+00:00 Use the existing image.\n",
            "2022-04-06 14:45:04+00:00 Generating deployment configuration.\n",
            "2022-04-06 14:45:05+00:00 Submitting deployment to compute.\n",
            "2022-04-06 14:45:09+00:00 Checking the status of deployment lgb-aci3..\n",
            "2022-04-06 14:45:29+00:00 Checking the status of inference endpoint lgb-aci3.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n"
          ]
        }
      ],
      "source": [
        "service.wait_for_deployment(show_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1649084385651
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2022-04-06T14:45:18,151287655+00:00 - iot-server/run \\n2022-04-06T14:45:18,152994579+00:00 - gunicorn/run \\nDynamic Python package installation is disabled.\\nStarting HTTP server\\n2022-04-06T14:45:18,453755549+00:00 - nginx/run \\n2022-04-06T14:45:18,452391231+00:00 - rsyslog/run \\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2022-04-06T14:45:22,054053936+00:00 - iot-server/finish 1 0\\n2022-04-06T14:45:22,149499568+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 20.1.0\\nListening at: http://127.0.0.1:31311 (13)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 38\\nSPARK_HOME not set. Skipping PySpark Initialization.\\nInitializing logger\\n2022-04-06 14:45:38,053 | root | INFO | Starting up app insights client\\nlogging socket was found. logging is available.\\nlogging socket was found. logging is available.\\n2022-04-06 14:45:38,054 | root | INFO | Starting up request id generator\\n2022-04-06 14:45:38,054 | root | INFO | Starting up app insight hooks\\n2022-04-06 14:45:38,054 | root | INFO | Invoking user\\'s init function\\n2022-04-06 14:45:38,152 | root | INFO | Users\\'s init has completed successfully\\n2022-04-06 14:45:38,252 | root | INFO | Skipping middleware: dbg_model_info as it\\'s not enabled.\\n2022-04-06 14:45:38,252 | root | INFO | Skipping middleware: dbg_resource_usage as it\\'s not enabled.\\n2022-04-06 14:45:38,253 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\\n2022-04-06 14:45:38,448 | root | INFO | Swagger file not present\\n2022-04-06 14:45:38,448 | root | INFO | 404\\n127.0.0.1 - - [06/Apr/2022:14:45:38 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\\n2022-04-06 14:45:43,038 | root | INFO | Swagger file not present\\n2022-04-06 14:45:43,038 | root | INFO | 404\\n127.0.0.1 - - [06/Apr/2022:14:45:43 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\\n'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "service.get_logs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Azure Machine Learning Studio にて正常に登録されていることを確認します。<br>\n",
        "<img src=\"../docs/images/azureml-deployment1.png\" width=500><br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## エンドポイントの利用 (Endpoint)\n",
        "推論環境にテストデータをインプットして、デプロイした機械学習モデルから予測値を算出します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Python SDK での手順"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1649082311275
        }
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import os\n",
        "import ssl\n",
        "\n",
        "# テストデータ\n",
        "data =  {\n",
        "            \"data\": [[\n",
        "                2,\n",
        "                \"Kvillner, Mr. Johan Henrik Johannesson\",\n",
        "                \"male\",\n",
        "                31,\n",
        "                0,\n",
        "                0,\n",
        "                \"C.A. 18723\",\n",
        "                10.5,\n",
        "                \"\",\n",
        "                \"S\"\n",
        "            ]]\n",
        "        }\n",
        "body = str.encode(json.dumps(data), encoding='utf8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1649082311281
        }
      },
      "outputs": [],
      "source": [
        "url = service.scoring_uri\n",
        "key, _ = service.get_keys()\n",
        "headers = {'Content-Type':'application/json'}\n",
        "headers[\"Authorization\"] = f\"Bearer {key}\"\n",
        "req = urllib.request.Request(url, body, headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1649082311289
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'[[0.7252904642292589, 0.2747095357707411]]'\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    response = urllib.request.urlopen(req)\n",
        "\n",
        "    result = response.read()\n",
        "    print(result)\n",
        "except urllib.error.HTTPError as error:\n",
        "    print(\"The request failed with status code: \" + str(error.code))\n",
        "\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
        "    print(error.info())\n",
        "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
