{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Azure Machine Learning による機械学習プロセス - デプロイ編"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## アジェンダ\n",
        "### A. 学習編\n",
        "- ワークスペース (Workspace) への接続\n",
        "- データセット (Datasets) の登録\n",
        "- 環境 (Environments) の登録\n",
        "- コンピューティングクラスター (Compute Clusters) の作成\n",
        "- モデル学習の実行と実験 (Run & Experiments)\n",
        "- モデル登録 (Models)\n",
        "\n",
        "### **B. デプロイ編 (本ノートブック)**\n",
        "- ワークスペース (Workspace) への接続\n",
        "- 推論環境の作成 (Deployment)\n",
        "- エンドポイントの利用 (Endpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 事前設定\n",
        "- 本ノートブックは Azure Machine Learning の Compute Instance を利用することを想定しています。\n",
        "- 予め [train-notebook.ipynb](train-notebook.ipynb) を実行して、モデル学習のジョブ実行と学習済みモデルの登録が完了していること。\n",
        "- カーネルは `azureml_py36 (Python 3.6.9)` を選択ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ワークスペース (Workspace) への接続\n",
        "作業環境から Azure Machine Learning Workspace へ接続を行います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Azure Machine Learning Studio\n",
        "[ml.azureml.com](ml.azurem.com) にアクセスします。Python SDK を中心に作業される場合にも Azure Machine Learning Studio を併用することが多いです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"../docs/images/azureml-workspace.png\" width=500>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Python SDK での手順\n",
        "クライアント環境の Python 環境にインストールした Azure ML Python SDK を用いて Azure Machine Learning Workspace に接続します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1643076002645
        }
      },
      "outputs": [],
      "source": [
        "# Compute Instance を利用する場合\n",
        "from azureml.core import Workspace\n",
        "ws = Workspace.from_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1643076002765
        }
      },
      "outputs": [],
      "source": [
        "# # その他の任意のクライアント環境を利用する場合\n",
        "# ws = Workspace.get(\n",
        "#     name='name',\n",
        "#     subscription_id='subscription_id',\n",
        "#     resource_group='resource_group',\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 推論環境の作成 (Deployment)\n",
        "下記の情報を利用してモデルをデプロイし、推論環境を作成します。\n",
        "- 登録済みのモデル (Model)\n",
        "- 推論環境で稼働する環境 (Environments)\n",
        "- 推論スクリプト : _score.py_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Python SDK での手順"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1643076002833
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.environment import Environment\n",
        "from azureml.core import Model\n",
        "from azureml.core.webservice import LocalWebservice, AciWebservice\n",
        "from azureml.core.model import InferenceConfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 登録済みのモデル (Models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1643076003071
        }
      },
      "outputs": [],
      "source": [
        "model = Model(ws, \"lgb-model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 推論環境で稼働する環境 (Environments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1643076003157
        }
      },
      "outputs": [],
      "source": [
        "env = Environment.get(ws, \"lightgbm-python-env\")\n",
        "env.inferencing_stack_version = 'latest'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 推論スクリプト _score.py_\n",
        "`script` フォルダに予め作成済みです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from helper import data_preprocess\n",
        "\n",
        "\n",
        "\n",
        "def init():\n",
        "    global bst\n",
        "    model_root = os.getenv(\"AZUREML_MODEL_DIR\")\n",
        "    # 学習済みモデルを含むフォルダ名の指定\n",
        "    lgbm_model_folder = \"model\"\n",
        "    bst = lgb.Booster(\n",
        "        model_file=os.path.join(model_root, lgbm_model_folder, \"model.lgb\")\n",
        "    )\n",
        "\n",
        "def run(raw_data):\n",
        "    categorical_cols = ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
        "    float_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "    columns = bst.feature_name()\n",
        "    data = np.array(json.loads(raw_data)[\"data\"])\n",
        "    test_df_original = pd.DataFrame(data=data, columns=columns)\n",
        "    test_df = data_preprocess(test_df_original, categorical_cols, float_cols)\n",
        "    # 予測値の生成\n",
        "    out = bst.predict(test_df)\n",
        "    return out.tolist()\n",
        "\n",
        "````"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "コードや環境 (Environments) の情報を設定します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1643076004226
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "inference_config = InferenceConfig(entry_script=\"score.py\", source_directory=\"script\", environment=env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "最初にローカル環境にデプロイをします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1643076027651
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "localconfig = LocalWebservice.deploy_configuration(port=8890)\n",
        "local_service_name = \"mylocalmodel\"\n",
        "local_service = Model.deploy(\n",
        "    workspace=ws,\n",
        "    name=local_service_name,\n",
        "    models=[model],\n",
        "    inference_config=inference_config,\n",
        "    deployment_config=localconfig,\n",
        "    overwrite=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1643076029176
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "local_service.wait_fordeployment(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "テストデータを入力して予測値を算出します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1643076029266
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# テストデータ\n",
        "data =  {\n",
        "            \"data\": [[\n",
        "                2,\n",
        "                \"Kvillner, Mr. Johan Henrik Johannesson\",\n",
        "                \"male\",\n",
        "                31,\n",
        "                0,\n",
        "                0,\n",
        "                \"C.A. 18723\",\n",
        "                10.5,\n",
        "                \"\",\n",
        "                \"S\"\n",
        "            ]]\n",
        "        }\n",
        "\n",
        "test_sample = json.dumps(data)\n",
        "test_sample = str.encode(test_sample, encoding='utf8')\n",
        "\n",
        "prediction = local_service.run(input_data=test_sample)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "次に Azure Container Instance へデプロイをします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1643075096254
        }
      },
      "outputs": [],
      "source": [
        "aciconfig = AciWebservice.deploy_configuration(auth_enabled=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Azure Container Instance にモデルをデプロイします。<br>\n",
        "なお、`service_name` は文字から始まる 3 以上 32 小文字・数字・記号 (ダッシュのみ)で記載ください。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1643075108327
        }
      },
      "outputs": [],
      "source": [
        "service_name = \"lgb-aci3\"  # グループで作業している場合は、名前を変更してください\n",
        "service = Model.deploy(\n",
        "    workspace=ws,\n",
        "    name=service_name,\n",
        "    models=[model],\n",
        "    inference_config=inference_config,\n",
        "    deployment_config=aciconfig,\n",
        "    overwrite=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "service.wait_for_deployment(show_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1643074788159
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "service.get_logs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Azure Machine Learning Studio にて正常に登録されていることを確認します。<br>\n",
        "<img src=\"../docs/images/azureml-deployment1.png\" width=500><br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## エンドポイントの利用 (Endpoint)\n",
        "推論環境にテストデータをインプットして、デプロイした機械学習モデルから予測値を算出します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Python SDK での手順"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import os\n",
        "import ssl\n",
        "\n",
        "# テストデータ\n",
        "data =  {\n",
        "            \"data\": [[\n",
        "                2,\n",
        "                \"Kvillner, Mr. Johan Henrik Johannesson\",\n",
        "                \"male\",\n",
        "                31,\n",
        "                0,\n",
        "                0,\n",
        "                \"C.A. 18723\",\n",
        "                10.5,\n",
        "                \"\",\n",
        "                \"S\"\n",
        "            ]]\n",
        "        }\n",
        "body = str.encode(json.dumps(data), encoding='utf8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "url = service.scoring_uri\n",
        "key, _ = service.get_keys()\n",
        "headers = {'Content-Type':'application/json'}\n",
        "headers[\"Authorization\"] = f\"Bearer {key}\"\n",
        "req = urllib.request.Request(url, body, headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    response = urllib.request.urlopen(req)\n",
        "\n",
        "    result = response.read()\n",
        "    print(result)\n",
        "except urllib.error.HTTPError as error:\n",
        "    print(\"The request failed with status code: \" + str(error.code))\n",
        "\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
        "    print(error.info())\n",
        "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
